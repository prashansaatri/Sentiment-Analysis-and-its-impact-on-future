# Sentiment-Analysis-and-its-impact-on-future
Artificial Intelligence Market Research - Sentiment Analysis at Google Nest and Amazon Echo



Introduction
Sentiment analysis plays a critical role in understanding the emotions, opinions, and attitudes expressed in customer feedback, social media trends, and brand reputation management. As leading tech companies in the market, Google and Amazon have developed their own machine learning models for sentiment analysis. This research proposal aims to investigate the current adoption, usage, and satisfaction levels of Google and Amazon's sentiment analysis machine learning models. The results of this study will provide valuable insights into the market demand and user experience of these tools, which can inform businesses in making data-driven decisions to enhance customer satisfaction, reputation management, and social media strategies.

Objectives:
The first goal is to adequately frame the contextual space that surrounds these technological developments;  how did this technology emerge and what solution or improvement does it hope to provide? From there, the next step is an exploration and elucidation of the technical details that make the application of sentiment analysis possible. Amazon and Google, as mega-cap tech companies, have broad coverage in scholarly articles and technological media – academic papers and articles that shed light on the model architectures in use should be available. This can be tied into the material that is being covered in class to estimate the ways sentiment analysis helps the two companies. The goals would be to identify user patterns as they relate to demand for products and the ways those findings inform marketing strategies. In order to better understand relative advantage, metrics surrounding accuracy and effectiveness will be used – of the two companies, is there one that is more likely to reliably predict sentiment? Once these understandings have been formed, the perspective of a regulatory role can be developed. Though a dizzying array of ethical questions warrant consideration, the main concerns are with the extent that their algorithms achieve the balance between the value sentiment analysis will likely produce (superior recommendations, increased sales) compared to the possible harm (inappropriate collection, storage and sale of personal data). Whichever company seems to be less balanced will be the one that is regulated. 

Methodology
To start, it is important to consider what consumers think about the development - and possible widespread deployment - of sentiment analysis. This would be accomplished by finding source surveys from market research. Ideally this research would include robust surveys that directly address sentiment analysis. However, these kinds of surveys may not be available. Should that be the case, surveys concerning technologies/products whose promised benefit required a corresponding sacrifice in privacy could be used to infer the same results. From there, as discussed within the objectives, publicly available materials surrounding Amazon/Google’s model architecture will be utilized. Hopefully, there are substantive differences in their approaches that, in conjunction with the class's material, will make it easier to determine which is likely to be superior from both a technical and ethical perspective. Lastly, if possible, a consultation with subject matter experts is warranted in order to see if their experience can better guide the contextual frameworks, which in turn gives a better basis to form regulatory recommendations. 

Conclusion
By accurately describing how the different stakeholders interact with sentiment analysis, the hope is to recommend better, rather than ideal, possible regulatory actions. The ability to do this hinges upon careful due diligence that yields a conceptual framework of sufficient resolution. Making good approximations of the models likely in use at Amazon and Google is necessary in order to provide relevant recommendations. Unfortunately, as a result of the many gaps in publicly available information, this will be a difficult task. Inferential leaps with regards to this kind of company sensitive material will have to be made. To the extent that these steps are performed successfully, relevant recommendations that describe less ethically fraught human/AI interactions can be suggested. 
